{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ec15bf-b21f-4870-a181-072d632dcd5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3667\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[3]\u001b[39m\u001b[92m, line 3\u001b[39m\n    import segmentation_models_pytorch as smp\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/segmentation_models_pytorch/__init__.py:2\u001b[39m\n    from . import encoders\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/segmentation_models_pytorch/encoders/__init__.py:2\u001b[39m\n    import timm\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/timm/__init__.py:8\u001b[39m\n    from .models import (\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/timm/models/__init__.py:46\u001b[39m\n    from .naflexvit import *\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/timm/models/naflexvit.py:195\u001b[39m\n    class NaFlexRopeIterator:\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/timm/models/naflexvit.py:231\u001b[39m in \u001b[95mNaFlexRopeIterator\u001b[39m\n    @disable_compiler\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/compiler/__init__.py:240\u001b[39m in \u001b[95mdisable\u001b[39m\n    import torch._dynamo\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/__init__.py:53\u001b[39m\n    from .polyfills import loader as _  # usort: skip # noqa: F401\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py:25\u001b[39m\n    POLYFILLED_MODULES: tuple[\"ModuleType\", ...] = tuple(\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py:26\u001b[39m in \u001b[95m<genexpr>\u001b[39m\n    importlib.import_module(f\".{submodule}\", package=polyfills.__name__)\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/importlib/__init__.py:90\u001b[39m in \u001b[95mimport_module\u001b[39m\n    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/polyfills/builtins.py:30\u001b[39m\n    @substitute_in_graph(builtins.all, can_constant_fold_through=True)\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/decorators.py:427\u001b[39m in \u001b[95mwrapper\u001b[39m\n    rule_map: dict[Any, type[VariableTracker]] = get_torch_obj_rule_map()\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:2870\u001b[39m in \u001b[95mget_torch_obj_rule_map\u001b[39m\n    obj = load_object(k)\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:2901\u001b[39m in \u001b[95mload_object\u001b[39m\n    val = _load_obj_from_str(x[0])\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:2885\u001b[39m in \u001b[95m_load_obj_from_str\u001b[39m\n    return getattr(importlib.import_module(module), obj_name)\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/importlib/__init__.py:90\u001b[39m in \u001b[95mimport_module\u001b[39m\n    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_higher_order_ops/map.py:6\u001b[39m\n    from torch._functorch.aot_autograd import AOTConfig, create_joint\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:135\u001b[39m\n    from .partitioners import default_partition\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_functorch/partitioners.py:37\u001b[39m\n    from ._activation_checkpointing.graph_info_provider import GraphInfoProvider\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/graph_info_provider.py:3\u001b[39m\n    import networkx as nx\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/networkx/__init__.py:23\u001b[39m\n    config = utils.backends._set_configs_from_environment()\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/networkx/utils/backends.py:134\u001b[39m in \u001b[95m_set_configs_from_environment\u001b[39m\n    backend_config = Config(**backend_config)\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/site-packages/networkx/utils/configs.py:82\u001b[39m in \u001b[95m__new__\u001b[39m\n    cls = dataclass(\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/dataclasses.py:1258\u001b[39m in \u001b[95mwrap\u001b[39m\n    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/dataclasses.py:1063\u001b[39m in \u001b[95m_process_class\u001b[39m\n    _init_fn(all_init_fields,\n",
      "  File \u001b[92m~/miniconda3/envs/ismd/lib/python3.12/dataclasses.py:619\u001b[39m in \u001b[95m_init_fn\u001b[39m\n    return _create_fn('__init__',\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ismd/lib/python3.12/dataclasses.py:473\u001b[39m\u001b[36m in \u001b[39m\u001b[35m_create_fn\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(txt, globals, ns)\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef __create_fn__(__dataclass_type_nx-loopback__, __dataclass_HAS_DEFAULT_FACTORY__, __dataclass_builtins_object__, __dataclass_return_type__):\u001b[39m\n                                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# notebooks/04_direct_model_training.ipynb\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Create bi-temporal U-Net with pre-trained ResNet34\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=6,  # 3 bands from time1 + 3 bands from time2\n",
    "    classes=1,      # Binary change detection\n",
    ")\n",
    "\n",
    "print(\"âœ… Bi-temporal U-Net created!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795025b-9e9d-41f9-ae2c-652258770095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
